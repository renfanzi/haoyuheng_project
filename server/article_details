#!/usr/bin/env python
# -*- coding:utf-8 -*-

import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from urllib import parse


def common_request(url):
    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'
    headers = {
        'User-Agent': user_agent,
    }
    content = requests.get(url, headers=headers).text
    return content


# 获取相似文献
def get_related(search_releated):
    related_url = "https://xueshu.baidu.com/usercenter/paper/search?wd=%s&type=related&rn=10&page_no=1" % search_releated
    related_data = json.loads(common_request(related_url), encoding="utf-8")
    # print(related_data)
    data = related_data["data"]
    data_papers = data["papers"]
    data_list = []
    for data_paper in data_papers:
        meta_di_info = data_paper.get("meta_di_info", '')
        if meta_di_info:
            # 这里获取详细信息
            # pdf链接
            sc_pdf_read = meta_di_info.get("sc_pdf_read", '')
            # 关键词
            sc_research = meta_di_info.get("sc_research", '')
            # 摘要
            sc_abstract = meta_di_info.get("sc_abstract", '')
            # 关键词
            sc_keyword = meta_di_info.get("sc_keyword", '')
            # 年份
            sc_year = meta_di_info.get("sc_year", '')
            # 标题
            sc_title = meta_di_info.get("sc_title", '')
            # 链接
            url = meta_di_info.get("url", '')
            # scholar url
            sc_scholarurl = meta_di_info.get("sc_scholarurl", '')
            # 作者
            sc_author = meta_di_info.get("sc_author", '')

            data_list.append({
                "sc_pdf_read": sc_pdf_read,
                "sc_research": sc_research,
                "sc_abstract": sc_abstract,
                "sc_keyword": sc_keyword,
                "sc_year": sc_year,
                "sc_title": sc_title,
                "url": url,
                "sc_scholarurl": sc_scholarurl,
                "sc_author": sc_author,
            })
    # print(data_list)
    return data_list


# 获取参考文献
def get_reference(search_reference):
    """
    result = {
        'msg': '操作成功',
        'status': 0,
        'data': {
            'curr_page_num': 0,
            'page_no': 1,
            'total_page_num': 2,
            'papers': [
                {'meta_di_info': {}},
                {'meta_di_info': {}},
                {'meta_di_info': {}},
            ]
        }
	}
    """
    reference_url = "https://xueshu.baidu.com/usercenter/paper/search?wd=citepaperuri:(%s)&type=reference&rn=10&page_no=1" % search_reference
    reference_data = json.loads(common_request(reference_url), encoding="utf-8")
    data = reference_data["data"]
    data_papers = data["papers"]
    data_list = []
    for data_paper in data_papers:
        meta_di_info = data_paper.get("meta_di_info", '')
        if meta_di_info:
            # 这里获取详细信息
            # pdf链接
            sc_pdf_read = meta_di_info.get("sc_pdf_read", '')
            # 关键词
            sc_research = meta_di_info.get("sc_research", '')
            # 摘要
            sc_abstract = meta_di_info.get("sc_abstract", '')
            # 关键词
            sc_keyword = meta_di_info.get("sc_keyword", '')
            # 年份
            sc_year = meta_di_info.get("sc_year", '')
            # 标题
            sc_title = meta_di_info.get("sc_title", '')
            # 链接
            url = meta_di_info.get("url", '')
            # scholar url
            sc_scholarurl = meta_di_info.get("sc_scholarurl", '')
            # 作者
            sc_author = meta_di_info.get("sc_author", '')

            data_list.append({
                "sc_pdf_read": sc_pdf_read,
                "sc_research": sc_research,
                "sc_abstract": sc_abstract,
                "sc_keyword": sc_keyword,
                "sc_year": sc_year,
                "sc_title": sc_title,
                "url": url,
                "sc_scholarurl": sc_scholarurl,
                "sc_author": sc_author,
            })
    # print(data_list)
    return data_list


# 获取单个详情页的数据
def get_simple_content(article_id, article_name):
    # 7e5d6765e44e4aba2bcb2b87dc0830bb
    simple_html_url = "https://xueshu.baidu.com/usercenter/paper/show?paperid=%s&site=xueshu_se" % article_id
    simple_html = common_request(simple_html_url)

    soup = BeautifulSoup(simple_html, "html.parser")
    # title : 标题（汽车空气动力学数值仿真研究进展）
    article_title = soup.find(name='a', attrs={"data-click": "{'act_block':'main','button_tp':'title'}"}).text.strip()
    print("标题：", article_title)
    # authors: 作者
    try:
        authors_soup_p = soup.find(name='p', attrs={"class": "author_text"})
        authors_a = authors_soup_p.find_all(name='a')
        # 获取作者链接
        # 获取作者名字
        authors_list = []
        for author_simple in authors_a:
            # 作者链接
            author_url = author_simple.get("href")
            # 作者姓名
            author_name = author_simple.text
            query = urlparse(author_url)[4]
            wd = parse.unquote(query)  # 解码字符串
            author_organization = wd.split("&")[0].split("=")[1]

            # 两种情况
            # 1. author:(张扬军) 清华大学&
            # 2. author:(张晋平) &
            if len(author_organization.split(' ')) > 1:
                author_organization = author_organization.split(' ')[1]
            else:
                author_organization = ''
            authors_list.append({
                "author_name": author_name,
                "author_organization": author_organization,
                "author_url": author_url,
            })
    except Exception as e:
        authors_list = ''
    print("作者：", authors_list)
    # 摘要
    article_abstract = soup.find(name='p', attrs={"class": "abstract"}).text.strip()
    print("摘要：", article_abstract)
    # 关键字
    try:
        keyword_soup_p = soup.find(name='p', attrs={"data-click": "{'button_tp':'keyword'}"})
        keyword_a = keyword_soup_p.find_all(name='a')
        keyword = [i.text.strip() for i in keyword_a]
    except Exception as e:
        keyword = ''
    print("关键字：", keyword)
    # DOI
    try:
        DOI = soup.find(name='p', attrs={"data-click": "{'button_tp':'doi'}"}).text.strip()
    except Exception as e:
        DOI = ''
    print("DOI:", DOI)
    # 被引用量
    # {'button_tp':'sc_cited'}
    try:
        sc_cited = soup.find(name='a', attrs={"data-click": "{'button_tp':'sc_cited'}"}).text.strip()
    except Exception as e:
        sc_cited = 0
    print("被引用量：", sc_cited)
    # 年份
    try:
        year = soup.find(name='p', attrs={"data-click": "{'button_tp':'year'}"}).text.strip()
    except Exception as e:
        year = 0
    print("年份：", year)
    # 来源期刊
    try:
        journal_title = soup.find(name='a', attrs={"data-click": "{'button_tp':'journal_title'}"}).text.strip()
    except Exception as e:
        journal_title = 0
    print("来源期刊：", journal_title)
    # 全部来源
    try:
        dl_item_span = soup.find_all(name='span', attrs={"class": "dl_item_span"})
        dl_list = []
        # 获取链接
        for i in dl_item_span:
            try:
                dl_item_href = i.find(name="a", attrs={"class": "dl_item"}).get("href")
                dl_item_title = i.find(name="span", attrs={"class": "dl_source"}).get("title")
                dl_list.append(
                    {
                        "dl_item_title": dl_item_title,
                        "dl_item_href": dl_item_href
                    }
                )
            except Exception as e:
                continue
    except Exception as e:
        dl_list = []
    print("全部来源:", dl_list)

    # 研究点分析
    try:
        sc_search_soup = soup.find_all(name='a', attrs={"data-click": "{'button_tp':'sc_search'}"})
        sc_search = [i.get("title") for i in sc_search_soup]
    except Exception as e:
        sc_search = ''
    print("研究点分析：", sc_search)

    # 相似文献
    try:
        related_data = get_related(article_name)
    except Exception as e:
        related_data = ''
    print("相似文献：", related_data)

    # 参考文献
    try:
        reference_data = get_reference(article_id)
    except Exception as e:
        reference_data = ''
    print("参考文献：", reference_data)


if __name__ == '__main__':
    # get_related("汽车空气动力学数值仿真研究进展")
    # get_reference("7e5d6765e44e4aba2bcb2b87dc0830bb")
    get_simple_content("7e5d6765e44e4aba2bcb2b87dc0830bb", "汽车空气动力学数值仿真研究进展")
